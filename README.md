# Self learning - AI&ML

## üìö Course Overview

This comprehensive self learning program provides hands-on experience in Artificial Intelligence and Machine Learning, covering fundamental concepts to advanced deep learning and natural language processing techniques. The program is designed to equip learners with practical skills through theoretical learning, video sessions, and real-world project implementations.

---

## üéØ Table of Contents

1. [Getting Started](#getting-started)
2. [Course Structure](#course-structure)
3. [Module 1: Machine Learning Fundamentals](#module-1-machine-learning-fundamentals)
4. [Module 2: Advanced ML - Regression](#module-2-advanced-ml---regression)
5. [Module 3: Advanced ML - Clustering Algorithms](#module-3-advanced-ml---clustering-algorithms)
6. [Module 4: Advanced ML - Classification Algorithms](#module-4-advanced-ml---classification-algorithms)
7. [Module 5: Advanced ML - Dimensionality Reduction](#module-5-advanced-ml---dimensionality-reduction)
8. [Module 6: Deep Learning - ANN](#module-6-deep-learning---ann)
9. [Module 7: Deep Learning - CNN](#module-7-deep-learning---cnn)
10. [Module 8: NLP Fundamentals](#module-8-nlp-fundamentals)
11. [Module 9: NLP Vector Transformation](#module-9-nlp-vector-transformation)
12. [Projects](#projects)
13. [Resources](#resources)

---

## üöÄ Getting Started

### Onboarding Process

**Date: October 18**

1. **Mandatory Intro Video**: Watch the introductory video to understand the self learning structure and expectations.
2. **Self Learning Start Guide**: Review the learning modules and project submission guidelines.
3. **Project Submission Form**: Familiarize yourself with the project submission process.

### Tips For Success

- Complete all video sessions in order
- Practice with provided demo codes
- Work on practical exercises after each module
- Submit projects on time
- Engage in discussions and ask questions
- Review notes before and after video sessions

---

## üìñ Course Structure

### Learning Path

```
Machine Learning Fundamentals
    ‚Üì
Advanced ML (Regression, Clustering, Classification, Dimensionality Reduction)
    ‚Üì
Deep Learning (ANN, CNN)
    ‚Üì
Natural Language Processing (Fundamentals, Vector Transformation)
    ‚Üì
Real-World Projects
```

---

## üìò Module 1: Machine Learning Fundamentals

### Overview

This module introduces the core concepts of machine learning, providing a solid foundation for advanced topics.

### Topics Covered

#### 1. **Introduction to Machine Learning**

- What is Machine Learning?
- Types of Learning: Supervised, Unsupervised, and Reinforcement Learning
- Machine Learning vs Traditional Programming
- Applications of ML in real-world scenarios

#### 2. **Data Preprocessing**

- Data Collection and Understanding
- Handling Missing Values
- Feature Engineering
- Data Normalization and Standardization
- Train-Test Split

#### 3. **Model Training and Evaluation**

- Model Selection
- Training Process
- Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)
- Overfitting and Underfitting
- Cross-Validation

#### 4. **Key Algorithms Introduction**

- Linear Regression
- Logistic Regression
- Decision Trees
- K-Nearest Neighbors (KNN)
- Support Vector Machines (SVM)

### Resources

- **Notes**: ML Fundamentals comprehensive notes
- **Video Sessions**:
  - Part 1: Introduction and Basics
  - Part 2: Data Preprocessing
  - Part 3: Model Training
  - Part 4: Evaluation Metrics
  - Part 5: Advanced Concepts
- **Demo Codes**:
  - Demo Code 1: Basic ML Pipeline
  - Demo Code 2: Model Evaluation

### Key Takeaways

- Understanding the ML workflow from data to predictions
- Importance of data quality and preprocessing
- Model evaluation and selection strategies
- Practical implementation of basic ML algorithms

---

## üìä Module 2: Advanced ML - Regression

### Overview

Deep dive into regression techniques for predicting continuous values, including regularization methods to prevent overfitting.

### Topics Covered

#### 1. **Linear Regression**

- Simple Linear Regression
- Multiple Linear Regression
- Assumptions of Linear Regression
- Cost Function and Gradient Descent
- R-squared and Adjusted R-squared

#### 2. **Regularization Techniques**

##### **Ridge Regression (L2 Regularization)**

- Concept of L2 penalty
- Lambda/Alpha parameter tuning
- When to use Ridge Regression
- Bias-Variance Trade-off

##### **Lasso Regression (L1 Regularization)**

- Concept of L1 penalty
- Feature Selection capability
- Comparison with Ridge
- Elastic Net as a combination

##### **Elastic Net**

- Combining L1 and L2 penalties
- Advantages over individual methods
- Hyperparameter tuning

#### 3. **Model Evaluation for Regression**

- Mean Squared Error (MSE)
- Root Mean Squared Error (RMSE)
- Mean Absolute Error (MAE)
- Residual Analysis

### Resources

- **Notes**: Complete Regression guide
- **Dataset**: Linear Regression Dataset
- **Video Sessions**:
  - Part 1: Linear Regression Fundamentals
  - Part 2: Advanced Linear Regression
  - Ridge, Lasso, Elastic Net
- **Practical Code**: Regression Practical Implementation
- **Video**: Regression Practical Demonstration

### Practical Implementation

The regression practical covers:

- Data loading and exploration
- Feature selection and engineering
- Model training with different regularization techniques
- Hyperparameter tuning
- Model comparison and selection
- Performance evaluation

### Key Takeaways

- Understanding when to use different regression techniques
- Importance of regularization in preventing overfitting
- Feature selection using Lasso regression
- Practical implementation and evaluation of regression models

---

## üîç Module 3: Advanced ML - Clustering Algorithms

### Overview

Explore unsupervised learning techniques for grouping similar data points without labeled data.

### Topics Covered

#### 1. **K-Means Clustering**

- Concept and Algorithm
- K-means initialization methods
- Choosing the optimal number of clusters (Elbow Method, Silhouette Score)
- Advantages and Limitations
- Applications in customer segmentation, image compression

#### 2. **Hierarchical Clustering**

- Agglomerative vs Divisive Clustering
- Linkage Methods (Single, Complete, Average, Ward)
- Dendrogram interpretation
- When to use Hierarchical Clustering

#### 3. **DBSCAN Clustering**

- Density-Based Clustering concept
- Core Points, Border Points, Noise Points
- Epsilon (Œµ) and MinPts parameters
- Advantages: Handles non-spherical clusters and noise
- Comparison with K-Means

### Resources

- **Notes**: Clustering Algorithms comprehensive guide
- **Video Sessions**:
  - K Means Clustering theory and implementation
  - K Means Clustering Practical
  - Hierarchical Clustering
  - DB Scan Clustering theory
  - DB Scan Clustering Practical
- **Code**:
  - K Means Clustering Practical Demonstration
  - DB Scan Clustering Practical Demonstration

### Practical Applications

- Customer Segmentation
- Image Segmentation
- Anomaly Detection
- Market Research
- Document Clustering

### Key Takeaways

- Understanding different clustering approaches
- Choosing appropriate clustering algorithm based on data characteristics
- Evaluating cluster quality
- Practical implementation of clustering algorithms

---

## üéØ Module 4: Advanced ML - Classification Algorithms

### Overview

Comprehensive study of classification algorithms for predicting categorical outcomes.

### Topics Covered

#### 1. **Logistic Regression**

- Binary and Multinomial Classification
- Sigmoid Function
- Maximum Likelihood Estimation
- Regularization in Logistic Regression

#### 2. **Decision Trees**

- Tree Construction (Entropy, Information Gain, Gini Impurity)
- Pruning techniques
- Advantages: Interpretability, No assumptions
- Limitations: Overfitting

#### 3. **Random Forest**

- Ensemble Learning concept
- Bagging technique
- Feature Importance
- Handling Overfitting

#### 4. **Support Vector Machines (SVM)**

- Maximum Margin Classifier
- Kernel Trick (Linear, Polynomial, RBF)
- Soft Margin SVM
- Multi-class Classification

#### 5. **Naive Bayes**

- Bayes Theorem
- Independence Assumption
- Different variants (Gaussian, Multinomial, Bernoulli)
- Text Classification applications

#### 6. **Gradient Boosting**

- Boosting concept
- XGBoost, LightGBM, CatBoost
- Hyperparameter tuning

### Resources

- **Notes**: Advanced ML Classification Algorithms
- **Dataset**: Loan Data dataset
- **Video Sessions**:
  - Classification Algorithm Part 1: Fundamentals
  - Classification Algorithms Part 2: Advanced Techniques
- **Project Sessions**:
  - Classification Algorithm Part 1: Implementation
  - Classification Algorithm Part 2: Advanced Project

### Project: Loan Approval Prediction

Using the Loan Data dataset to predict loan approval status, covering:

- Data preprocessing for classification
- Feature engineering
- Model selection and comparison
- Handling imbalanced datasets
- Model evaluation metrics

### Key Takeaways

- Understanding various classification algorithms
- Choosing the right algorithm for specific problems
- Handling imbalanced datasets
- Model evaluation for classification problems
- Practical project implementation

---

## üìâ Module 5: Advanced ML - Dimensionality Reduction

### Overview

Techniques to reduce the number of features while preserving important information, improving model performance and interpretability.

### Topics Covered

#### 1. **Principal Component Analysis (PCA)**

- Variance maximization concept
- Eigenvalues and Eigenvectors
- Explained Variance Ratio
- Choosing the number of components
- Applications: Data visualization, Noise reduction

#### 2. **Linear Discriminant Analysis (LDA)**

- Supervised dimensionality reduction
- Maximizing class separability
- Comparison with PCA
- Applications in classification

#### 3. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**

- Non-linear dimensionality reduction
- Preserving local structure
- Visualization applications
- Hyperparameter tuning (perplexity)

#### 4. **Independent Component Analysis (ICA)**

- Finding independent sources
- Applications in signal processing

### Resources

- **Notes**: Dimensionality Reduction comprehensive guide
- **Video Session**: Dimensionality Reduction theory and implementation

### When to Use Dimensionality Reduction

- High-dimensional datasets (curse of dimensionality)
- Visualization needs
- Reducing computational complexity
- Removing multicollinearity
- Feature extraction

### Key Takeaways

- Understanding the curse of dimensionality
- Choosing appropriate dimensionality reduction technique
- Trade-offs between information loss and model simplicity
- Practical implementation and visualization

---

## üß† Module 6: Deep Learning - ANN (Artificial Neural Networks)

### Overview

Introduction to deep learning through Artificial Neural Networks, the foundation of modern AI.

### Topics Covered

#### 1. **Neural Network Fundamentals**

- Perceptron and Multi-layer Perceptron (MLP)
- Activation Functions (Sigmoid, Tanh, ReLU, Leaky ReLU)
- Forward Propagation
- Backpropagation Algorithm
- Gradient Descent and its variants

#### 2. **Network Architecture**

- Input Layer, Hidden Layers, Output Layer
- Choosing the number of layers and neurons
- Weight Initialization
- Bias Terms

#### 3. **Training Deep Networks**

- Loss Functions (MSE, Cross-Entropy)
- Optimizers (SGD, Adam, RMSprop, Adagrad)
- Learning Rate Scheduling
- Batch Size considerations
- Epochs and Iterations

#### 4. **Regularization Techniques**

- Dropout
- L1/L2 Regularization
- Early Stopping
- Batch Normalization
- Data Augmentation

#### 5. **Hyperparameter Tuning**

- Learning Rate
- Batch Size
- Number of Layers and Neurons
- Activation Functions
- Optimizer Selection

### Resources

- **Notes**: Deep Learning Fundamentals
- **Dataset**: Dataset CSV
- **Video Sessions**:
  - Part 1: Introduction to Neural Networks
  - Part 2: Backpropagation and Training
  - Part 3: Activation Functions and Architecture
  - Part 4: Advanced Topics
- **Practical Session**: Deep Learning Fundamental hands-on
- **Code**: Deep Learning Fundamental implementation

### Practical Implementation Example

The practical code demonstrates:

- Data preprocessing and scaling
- Building a Sequential model with multiple hidden layers
- Using ReLU activation for hidden layers
- Sigmoid activation for binary classification output
- Early stopping to prevent overfitting
- Model compilation with Adam optimizer
- Training with validation split
- Visualizing training history (loss and accuracy)

```python
# Example Architecture
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=11))  # First hidden layer
model.add(Dense(32, activation='relu'))                # Second hidden layer
model.add(Dense(1, activation='sigmoid'))              # Output layer
```

### Key Takeaways

- Understanding how neural networks learn
- Building and training deep learning models
- Preventing overfitting with regularization
- Optimizing hyperparameters
- Practical implementation with TensorFlow/Keras

---

## üñºÔ∏è Module 7: Deep Learning - CNN (Convolutional Neural Networks)

### Overview

Specialized neural networks for image processing and computer vision tasks.

### Topics Covered

#### 1. **CNN Architecture**

- Convolutional Layers
- Pooling Layers (Max Pooling, Average Pooling)
- Fully Connected Layers
- Feature Maps and Filters

#### 2. **Convolution Operation**

- Kernel/Filter concept
- Stride and Padding
- Feature Detection
- Spatial Hierarchies

#### 3. **Popular CNN Architectures**

- LeNet
- AlexNet
- VGG
- ResNet
- Transfer Learning

#### 4. **Deep Learning Optimizers**

- Stochastic Gradient Descent (SGD)
- Adam Optimizer
- RMSprop
- Adagrad
- Learning Rate Decay

#### 5. **Image Preprocessing**

- Image Augmentation
- Normalization
- Resizing and Cropping
- Data Generators

### Resources

- **Notes**:
  - Deep Learning Optimizers
  - CNN comprehensive guide
- **Video Sessions**:
  - Deep Learning Optimizers
  - Deep Learning CNN theory and implementation
- **Dataset**: CNN dataset
- **Project Session**: CNN practical project

### Applications

- Image Classification
- Object Detection
- Face Recognition
- Medical Image Analysis
- Autonomous Vehicles

### Key Takeaways

- Understanding CNN architecture and operations
- Building CNN models for image classification
- Using transfer learning for better performance
- Optimizing CNN training
- Practical project implementation

---

## üí¨ Module 8: NLP Fundamentals

### Overview

Introduction to Natural Language Processing, enabling machines to understand and process human language.

### Topics Covered

#### 1. **Introduction to NLP**

- What is NLP?
- Applications: Sentiment Analysis, Machine Translation, Chatbots, Text Summarization
- Challenges in NLP: Ambiguity, Context, Sarcasm

#### 2. **Text Preprocessing**

- Tokenization
- Lowercasing
- Removing Punctuation
- Stop Words Removal
- Stemming vs Lemmatization
- Handling Special Characters and Numbers

#### 3. **Text Representation**

- Bag of Words (BoW)
- N-grams
- TF-IDF (Term Frequency-Inverse Document Frequency)
- Limitations of traditional methods

#### 4. **Basic NLP Tasks**

- Text Classification
- Named Entity Recognition (NER)
- Part-of-Speech Tagging
- Sentiment Analysis

### Resources

- **Notes**: NLP Fundamentals comprehensive guide
- **Video Session**: NLP Fundamental theory and applications

### Key Takeaways

- Understanding the importance of text preprocessing
- Basic text representation techniques
- Introduction to NLP applications
- Foundation for advanced NLP techniques

---

## üî§ Module 9: NLP Vector Transformation

### Overview

Advanced techniques for converting text into numerical vectors that capture semantic meaning.

### Topics Covered

#### 1. **Traditional Vectorization Methods**

##### **Bag of Words (BoW)**

- Document-term matrix
- Sparse representation
- Limitations: No word order, No semantic meaning

##### **TF-IDF (Term Frequency-Inverse Document Frequency)**

- Term Frequency calculation
- Inverse Document Frequency
- TF-IDF formula and interpretation
- Advantages over BoW

#### 2. **Word Embeddings**

##### **Word2Vec**

- Continuous Bag of Words (CBOW)
- Skip-gram model
- Pre-trained word vectors
- Semantic relationships

##### **GloVe (Global Vectors)**

- Global matrix factorization
- Combining global and local statistics
- Comparison with Word2Vec

##### **FastText**

- Subword information
- Handling out-of-vocabulary words
- Character n-grams

#### 3. **Contextual Embeddings**

- Introduction to Transformer models
- BERT, GPT, and modern embeddings
- Context-aware representations

#### 4. **Practical Applications**

- Text Classification
- Sentiment Analysis
- Spam Detection
- Document Similarity

### Resources

- **Notes**: Vector Transformation comprehensive guide
- **Dataset**: SMS Spam Collection
- **Video Sessions**:
  - Part 1: Traditional Methods (BoW, TF-IDF)
  - Part 2: Word Embeddings Introduction
  - Part 3: Word2Vec and GloVe
  - Part 4: Advanced Embeddings
- **Practical Session**: Vector Transformation hands-on
- **Code**: NLP Vector Transformation implementation

### Project: SMS Spam Detection

Using the SMS Spam Collection dataset to:

- Preprocess text data
- Apply different vectorization techniques
- Compare BoW, TF-IDF, and Word Embeddings
- Build classification models
- Evaluate performance

### Key Takeaways

- Understanding different text vectorization methods
- Choosing appropriate technique based on task
- Implementing word embeddings
- Practical application in text classification
- Comparison of different approaches

---

## üéì Projects

### Available Projects

#### 1. **Credit Card Fraud Detection**

- **Objective**: Detect fraudulent credit card transactions
- **Techniques**: Anomaly detection, Classification algorithms
- **Challenges**: Highly imbalanced dataset
- **Evaluation**: Precision, Recall, F1-Score, ROC-AUC

#### 2. **Customer Churn Prediction for Telecom**

- **Objective**: Predict which customers are likely to churn
- **Techniques**: Classification, Feature engineering
- **Business Impact**: Customer retention strategies
- **Evaluation**: Accuracy, Precision, Recall

#### 3. **Sales Forecasting for Retail**

- **Objective**: Predict future sales for retail businesses
- **Techniques**: Time series analysis, Regression
- **Applications**: Inventory management, Demand planning
- **Evaluation**: RMSE, MAE, MAPE

#### 4. **Medical Image Classification for Disease Detection**

- **Objective**: Classify medical images for disease detection
- **Techniques**: CNN, Transfer Learning
- **Applications**: Healthcare, Early diagnosis
- **Evaluation**: Accuracy, Sensitivity, Specificity

#### 5. **Energy Consumption Optimization**

- **Objective**: Optimize energy consumption patterns
- **Techniques**: Regression, Time series, Clustering
- **Applications**: Smart grids, Sustainability
- **Evaluation**: RMSE, Energy savings metrics

#### 6. **Sentiment Analysis for Product Reviews**

- **Objective**: Analyze sentiment of product reviews
- **Techniques**: NLP, Text Classification, Word Embeddings
- **Applications**: Business intelligence, Customer feedback
- **Evaluation**: Accuracy, F1-Score, Confusion Matrix

#### 7. **Stock Price Prediction**

- **Objective**: Predict future stock prices
- **Techniques**: Time series analysis, LSTM, Regression
- **Challenges**: Market volatility, Non-stationarity
- **Evaluation**: RMSE, Directional Accuracy

#### 8. **Traffic Sign Recognition for Autonomous Vehicles**

- **Objective**: Recognize and classify traffic signs
- **Techniques**: CNN, Image Processing
- **Applications**: Self-driving cars, Safety
- **Evaluation**: Accuracy, Real-time performance

#### 9. **Fake News Detection**

- **Objective**: Identify fake news articles
- **Techniques**: NLP, Text Classification, Feature Engineering
- **Applications**: Media verification, Information integrity
- **Evaluation**: Precision, Recall, F1-Score

### Project Submission Guidelines

1. **Code Quality**

   - Clean, well-commented code
   - Proper structure and organization
   - Use of best practices

2. **Documentation**

   - README with project description
   - Explanation of approach
   - Results and insights

3. **Analysis**

   - Exploratory Data Analysis (EDA)
   - Feature engineering rationale
   - Model selection justification

4. **Results**

   - Model performance metrics
   - Visualizations
   - Business insights

5. **Submission**
   - Use the Project Submission Form
   - Include code, documentation, and results
   - Meet submission deadlines

---

## üìö Resources

### Essential Libraries

#### Machine Learning

- `scikit-learn`: Machine learning algorithms
- `pandas`: Data manipulation
- `numpy`: Numerical computing
- `matplotlib`: Data visualization
- `seaborn`: Statistical visualization

#### Deep Learning

- `tensorflow`: Deep learning framework
- `keras`: High-level neural networks API
- `pytorch`: Alternative deep learning framework

#### NLP

- `nltk`: Natural Language Toolkit
- `spaCy`: Advanced NLP library
- `gensim`: Topic modeling and word embeddings

### Datasets

- Linear Regression Dataset
- Loan Data dataset
- CNN dataset
- SMS Spam Collection
- Various project-specific datasets

### Learning Path Recommendations

1. **Beginner Path**

   - Start with ML Fundamentals
   - Practice with demo codes
   - Work on simple projects

2. **Intermediate Path**

   - Complete Advanced ML modules
   - Implement practical exercises
   - Work on classification/regression projects

3. **Advanced Path**
   - Deep Learning modules
   - NLP modules
   - Complex projects (CNN, NLP applications)

### Best Practices

1. **Code Organization**

   - Use functions and classes
   - Add comments and docstrings
   - Follow PEP 8 (Python style guide)

2. **Version Control**

   - Use Git for version control
   - Commit frequently with meaningful messages
   - Create branches for experiments

3. **Experimentation**

   - Keep a log of experiments
   - Document hyperparameters
   - Compare different approaches

4. **Documentation**
   - Document your code
   - Explain your approach
   - Include visualizations and insights

---

## üéØ Learning Objectives

By the end of this self learning program, you will be able to:

1. ‚úÖ Understand fundamental machine learning concepts
2. ‚úÖ Implement various ML algorithms (Regression, Classification, Clustering)
3. ‚úÖ Apply dimensionality reduction techniques
4. ‚úÖ Build and train deep neural networks (ANN, CNN)
5. ‚úÖ Process and analyze text data using NLP techniques
6. ‚úÖ Complete end-to-end ML projects
7. ‚úÖ Evaluate and optimize model performance
8. ‚úÖ Apply ML techniques to real-world problems

---

## üìù Notes

- Complete all video sessions in sequence
- Practice with provided code examples
- Work on practical exercises after each module
- Submit projects on time
- Engage in discussions and ask questions
- Review notes regularly
- Experiment with different approaches
- Document your learning journey

---

## ü§ù Support

For questions, clarifications, or assistance:

- Review video sessions and notes
- Check practical code examples
- Engage in course discussions
- Reach out through the self learning platform

---

## üèÜ Success Tips

1. **Consistency**: Study regularly and practice daily
2. **Hands-on Practice**: Code along with video sessions
3. **Projects**: Apply concepts in real projects
4. **Documentation**: Keep notes and document your learning
5. **Community**: Engage with fellow learners
6. **Experimentation**: Try different approaches and techniques
7. **Review**: Regularly review previous modules
8. **Patience**: Deep learning takes time, be patient with the process

---

## üìÑ License

This course material is provided for self learning purposes.

---

**Good luck with your AI & ML learning journey! üöÄ**

_Last Updated: January 2025 by Priyanka Gowda_
